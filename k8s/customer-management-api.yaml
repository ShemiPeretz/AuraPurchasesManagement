# Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: customer-management-api
  namespace: ecommerce-system
  labels:
    app: customer-management-api
    component: consumer
    tier: backend
spec:
  replicas: 1
  selector:
    matchLabels:
      app: customer-management-api
  template:
    metadata:
      labels:
        app: customer-management-api
        component: consumer
        tier: backend
    spec:
      containers:
      - name: api
        image: customer-management-api:latest
        imagePullPolicy: IfNotPresent

        ports:
        - containerPort: 8001
          name: http
          protocol: TCP

        # Environment variables from ConfigMap
        env:
        - name: MONGODB_URI
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: MONGODB_URI
        - name: MONGODB_DB_NAME
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: MONGODB_DB_NAME
        - name: MONGODB_COLLECTION
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: MONGODB_COLLECTION
        - name: KAFKA_BOOTSTRAP_SERVERS
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: KAFKA_BOOTSTRAP_SERVERS
        - name: KAFKA_TOPIC
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: KAFKA_TOPIC
        - name: KAFKA_GROUP_ID
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: KAFKA_GROUP_ID
        - name: LOG_LEVEL
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: LOG_LEVEL

        # Resource requests and limits
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"

        # Liveness probe - is the app alive?
        # If this fails, Kubernetes will restart the pod
        livenessProbe:
          httpGet:
            path: /health
            port: 8001
          initialDelaySeconds: 60  # Wait for Kafka consumer to initialize
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3

        # Readiness probe - is the app ready to serve traffic?
        # If this fails, pod is removed from service endpoints
        readinessProbe:
          httpGet:
            path: /health
            port: 8001
          initialDelaySeconds: 30
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3

        # Startup probe - give app time to start
        startupProbe:
          httpGet:
            path: /health
            port: 8001
          initialDelaySeconds: 10
          periodSeconds: 5
          failureThreshold: 12  # Allow 60 seconds to start (12 * 5)

---
# Service
apiVersion: v1
kind: Service
metadata:
  name: customer-management-service
  namespace: ecommerce-system
  labels:
    app: customer-management-api
spec:
  type: ClusterIP
  ports:
  - port: 8001
    targetPort: 8001
    protocol: TCP
    name: http
  selector:
    app: customer-management-api

---

apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: customer-management-api-scaledobject
  namespace: ecommerce-system
  labels:
    app.kubernetes.io/name: customer-management-api
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: customer-management-api
  pollingInterval: 10
  cooldownPeriod: 60
  minReplicaCount: 1
  maxReplicaCount: 5
  triggers:
    - type: kafka
      metadata:
        bootstrapServers: kafka-service.ecommerce-system.svc.cluster.local:29092
        consumerGroup: customer-management-group
        topic: purchases
        # --- NEW FIELD: Explicitly set the protocol ---
        protocol: plaintext
        # --- NEW FIELD: Client ID for better tracking ---
        clientID: keda-autoscaler-client
        # Target: average lag of 50 messages per consumer instance.
        lagThreshold: "50"
        offsetResetPolicy: latest
    - type: cpu
      metadata:
        # KEDA requires a "type" field inside the metadata for resource scalers.
        type: Utilization
        value: "70" # Target 70% CPU utilization